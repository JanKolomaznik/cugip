<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>CUGIP: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">CUGIP
   </div>
   <div id="projectbrief">CUDA Generic Image Processing</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">CUGIP Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="intro_sec"></a>
Introduction</h1>
<p>CUDA itself provide only low-level API, and data structures designed only to control the computation.</p>
<p>Set of STL-like data structures and algorithms for developing high-performance parallel applications with minimal programming effort is provided by library <a href="http://docs.nvidia.com/cuda/thrust/" title="Thrust">Thrust</a>.</p>
<p>Parallelized version of the Fast Fourier Transform is available in {CUFFT}, accelerated image and video processing are provided in <a href="http://docs.nvidia.com/cuda/npp/" title="NPP">NVidia Performance Primitives - NPP</a>. All these libraries and lots of others are part of the CUDA toolkit. However, none of these libraries provides tools for developing new parallel algorithms for image processing, as most of the utilities wrap device code and provide only host interface. The only exception is the Thrust library, which provides meta-algorithms allowing a passing of the functors, which are then executed on a device. However, Thrust library is focused only on one-dimensional data structures, moreover, does not know image processing concepts like pixel/voxel neighborhood,.</p>
<p>From this comes the motivation in developing a new library for image processing using CUDA. The <em>CUDA Generic Image Processing</em> library was designed with following goals in mind:</p>
<ul>
<li>Simple device &harr; host transfers</li>
<li>Minimal overhead in comparison to using plain CUDA</li>
<li>Cover common algorithmic patterns - kernel execution, image arithmetics, reduce, scan. etc.</li>
<li>Manage device memory allocations</li>
<li>Hide the CUDA API complexity</li>
<li>Error handling using exceptions &ndash; strong exception guarantees where possible (plain CUDA uses error codes)</li>
<li>Resource Acquisition Is Initialization (RAII) wrappers</li>
<li>Easy interoperability with other image processing libraries (successfully used with ITK and Numpy for example)</li>
</ul>
<h1><a class="anchor" id="concepts_sec"></a>
Concepts</h1>
<p>A key aspect of the library design is memory management. Latest version of CUDA (CUDA 8 at the time of writing) does not yet support memory swapping (operating system does that for the whole process in context switch), so when physical memory is depleted during computation then next allocation fails, and so does the rest of the computation.</p>
<p>Algorithm which should work for wide range of task sizes and device configuration should be aware of its memory requirements and if it is possible to do whole computation with memory available for allocation. If there is not enough memory, usually the tasks are split to small subtasks that can be successfully executed.</p>
<p>With that in mind, the library was designed, so that no allocations happen without users knowledge if possible. It means that if some meta-algorithm needs storage for temporary results, the user has an option to pass pre-allocated temporary buffer.</p>
<p>This requirement also enforces that data passed to algorithms are handled by non-owning data structures (views) and owners do not appear inside the library calls.</p>
<p>In CUGIP library most of the processed data are images of some sort. So the terminology is as follows &ndash; owning data structures are {images} and non-owning data structures, which provide access to image data are {image views}. The interface implementation is inspired by {Generic Image Library (GIL)} by Adobe <b>[Adobe2009]</b>}. It follows the basic C++ idiom {Resource Acquisition Is Inititalization} (<b>[Stroustrup1994]</b>}) or {RAII}, binding the lifetime of the owning data structures (images) to the stack.</p>
<p>Basic primitive to access data is an image view. Iterators like the ones from STL or more image oriented iterators from {Insight Toolkit} &ndash; ITK (<b>[Kitware2016]</b>}) are not used because the usual semantics of iterator concept provides sequential access (iteration over range specified by begin and end). Iterators simply do not map well to multi-threaded processing. For a small number of threads the range can be divided into subranges and in each the processing switches back to the sequential processing, as can be seen for n-dimensional ranges in the Intel library {Threading Building Blocks} (<b>[Intel2016]</b>}).</p>
<p>All the reasons for these design decisions will be discussed in following sections in more depth.</p>
<h2><a class="anchor" id="images_sec"></a>
Images</h2>
<p>The image is a container which owns a memory block containing pixel/voxel data. It allocates data in a constructor and deallocates in a destructor. Image data are accessed by provided image views - {const_view(image)} for read-only access and {view(image)} for read/write access.</p>
<p>There are several types of images based on the type of the memory it allocates from. All image types are created in the host code (CPU code). Because images are data owning data structures, it would be complicated to prevent unintentional copies to be generated as CUDA uses raw memory copying instead of calling copy constructors.</p>
<p>In general, CUDA kernels and device code can only access images through provided device accessible image views (device code cannot access host memory).</p>
<h3><a class="anchor" id="host_image_sec"></a>
Host Image</h3>
<p>For data allocated in host memory, the generic {<a class="el" href="classcugip_1_1host__image.html">cugip::host_image</a>} is provided. It is a templated by type of an image element (pixel/voxel) and dimension of the image (2D and 3D images are currently supported). Since data are allocated in the host memory (RAM), they can be easily accessed by the provided image views from host code. The internal memory buffer can be accessed directly by provide pointer, but users must be aware that image owns the data, so the pointer is invalidated in the destructor and possibly during image resize.</p>
<h3><a class="anchor" id="device_image_sec"></a>
Device Image</h3>
<p>Similar to HostImage, but the internal data buffer is allocated as a linear device (GPU) memory. Implemented by generic {<a class="el" href="classcugip_1_1device__image.html">cugip::device_image</a>}. Because the data live on GPU, it is accessible from device code by provided image views.</p>
<h3><a class="anchor" id="texture_image_sec"></a>
Texture Image</h3>
<p>Similar to the {<a class="el" href="classcugip_1_1device__image.html">cugip::device_image</a>}, it contains data accessible from device code, but data are allocated in texture memory and accessed through bindless texture interface (added in CUDA 5.0). Texture memory has different caching properties as compared to linear memory, moreover, provides additional utilities, such as normalized floating point access, element interpolation, and mipmapping. These features are directly supported by the hardware and thus faster than a manual implementation.</p>
<h3><a class="anchor" id="variant_image_sec"></a>
Variant Image</h3>
<p>As the CUGIP library is written in C++, which is a strongly typed language, and demand on low overhead led to an elimination of the virtual methods in the CUGIP interfaces. There is often need to use multiple images of different types, which are not mutually compatible. If the images are not needed at the same moment, there would be lots of allocations and deallocations when switching between these image types if there is not enough memory. To prevent this a meta image called {cugip::variant_image} is created, which uses a single internal buffer and provides views of different types (specified at a compile time). This overcomes the problem of the repeated allocation and deallocation and still provides compile time safety (contrary to using only void pointer based interfaces).</p>
<h2><a class="anchor" id="views_sec"></a>
Views</h2>
<p>CUGIP is designed in a way that all accesses to image data are done through image views. Image views are lightweight memcopyable non-owning containers. They are used in a similar manner as iterators in STL. Since iterators themselves are an not ideal solution in a parallel environment, data views were chosen in CUGIP implementation as the most suitable replacement.</p>
<p>Image view concept is bound to a notion of a zero based n-dimensional interval. For each point from the n-dimensional interval an access to image element (whether read or read/write depends on the type of view) is provided.</p>
<h3><a class="anchor" id="host_image_views_sec"></a>
Host Image View</h3>
<p>Host image views are views returned either by host image instances or by generating subview from already available host view.</p>
<h3><a class="anchor" id="device_image_view_sec"></a>
Device Image View</h3>
<p>Similar to host image views - created either by device image or by getting subview of already created device image view.</p>
<p>Both host and device image views are referenced as memory based views as they both access element through pointers in linear memory.</p>
<h3><a class="anchor" id="memory_views_sec"></a>
Memory Views</h3>
<p>Essential concept are memory views. These objects provide access to values stored in host or device memory. Passing data between host and device code, and other APIs requiring pointer access to data (CUFFT &ndash; <b>[NVIDIACorporation2015c]</b>}) can happen only through memory views, which access the data through a base pointer, size and stride attributes.</p>
<p>Another important feature of memory based views is that generating slice view or subview of the memory based view does not create a wrapper class around the original view, but recalculates base pointer, size and strides to give access to a correct subregion of the original view and creates a new memory-based view with these attributes.</p>
<h3><a class="anchor" id="procedural_views_sec"></a>
Procedural Views</h3>
<p>Procedural views are quite different from memory based views as they do not provide a direct memory access. Instead, they either generate the value based on their arguments and provided an index or do some on-demand operation on a wrapped view of a different type. These views are lazily evaluated &ndash; returned value is not computed until the position is accessed.</p>
<p>In lots of situations, the same result can be achieved by using meta-algorithms to compute some output data. However, if an algorithm has several steps, it would mean several kernel executions. By using lazy views, all required operations can be bundled in one procedural view and provide the result in single kernel execution, thus lowering the overhead.</p>
<p>A model situation when this approach pays off is image algebra.</p>
<h1><a class="anchor" id="lazy_evaluation_sec"></a>
Lazy evaluation</h1>
<p>When a code is optimized for speed one of the first steps is an elimination of the slowest operation. Slowest operation depends on the context. Years back was one of the optimization replacement of multiplications by additions. This kind of optimizations is nowadays done mostly by compilers if necessary (additions and multiplications are instructions of the same length in modern processors), but the principle stays &ndash; expensive mathematical functions are replaced by fetching values from precomputed tables or using approximations of sufficient precision.</p>
<p>In CUDA world one of the slowest operations is kernel execution. For complex kernels, the time needed for their execution is often irrelevant. However, if the kernel is lightweight &ndash; for example some simple arithmetic operation on input data &ndash; its execution can be expensive. So it is a good idea to bundle these simple kernels into one and execute it only once or provide the value on demand.</p>
<h1><a class="anchor" id="metaalgorithms_sec"></a>
Meta-algorithms</h1>
<p>Several STL-like meta algorithms are provided, hiding kernel (or several kernels) execution for common computation patterns. This is similar to what Thrust does for 1D data structures.</p>
<h2><a class="anchor" id="copy_sec"></a>
Copy</h2>
<p>{<a class="el" href="namespacecugip.html#a8f8bd893f8d06a9e9f4d89eadc610d03">cugip::copy</a>} and {cugip::copy_async} meta-algorithms generally serve for copying data between views of the same size, but there are some restrictions:</p><ul>
<li>When copying between device and host based views, only memory based views can be used.</li>
<li>Procedural and lazily evaluated views can only be copied only in device-device or host-host transactions.</li>
</ul>
<h2><a class="anchor" id="for_each_sec"></a>
For Each</h2>
<p>One of the principal operations on an image is to apply a function on all image elements from provided image view. It has similar semantics as {<a class="el" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">std::for_each()</a>} from STL.</p>
<p>The basic version takes unary callable (function, functor) and applies it to all elements and stores the result in-place. Although the variant without an update (procedure instead of a function) is often used in STL for gathering information about the values from processed iterator range, it is not an efficient approach in CUDA (and parallel processing in general) because it would require intensive synchronization of the threads when updating internal data of the callable. Better approach is to use parallel reduce for this kind of task, which handles synchronization in a hierarchical manner and is thus usually far more efficient.</p>
<p>Another variant of the {<a class="el" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">for_each()</a>} algorithm takes binary callable, which operates on an element value and its index in the processed image view, making it possible to return value dependent on a position in the image.</p>
<p>As other meta-algorithms, it can be executed on specified stream and its behavior in the sense of multithreading (block and grid sizes) can be modified by providing policy class.</p>
<p>The only variant of the {<a class="el" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">for_each()</a>} algorithm, which gives access to the neighborhood of image element through locators, works only for read-only functors. The reason is the possible race conditions coming from the concurrent access to the image elements and storing the results in-place. There would be no certainty whether the value returned by locator for some non-zero offset would return original value or newly computed value.</p>
<div class="fragment"><div class="line">device_image&lt;int, 3&gt; deviceImage(256, 256, 256);</div><div class="line"><span class="comment">// fill deviceImage ...</span></div><div class="line"></div><div class="line"><span class="comment">// apply lambda function on each voxel </span></div><div class="line"><span class="comment">// and increase its value by one </span></div><div class="line"><a class="code" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">for_each</a>(</div><div class="line">      <a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">view</a>(deviceImage), </div><div class="line">      []__device__(<span class="keywordtype">int</span> arg) { </div><div class="line">            <span class="keywordflow">return</span> arg + 1; </div><div class="line">      });</div></div><!-- fragment --><h2><a class="anchor" id=""></a>
</h2>
<p>As {<a class="el" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">for_each()</a>} does in-place processing of the input image view, the {<a class="el" href="group__meta__algorithm.html#gaf90e6c7b7e426bceecd429783ab79f79">transform()</a>} algorithm and its variants process the input view (or views) and stores the result in an output view. The basic variants works similarly to {<a class="el" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">for_each()</a>} &ndash; it takes unary callable and result of each execution stores as output, but now it can be of different type to input element.</p>
<div class="fragment"><div class="line">device_image&lt;int, 3&gt; deviceImage(256, 256, 256);</div><div class="line">device_image&lt;float, 3&gt; resultImage(256, 256, 256);</div><div class="line"><span class="comment">// fill deviceImage ...</span></div><div class="line"></div><div class="line"><span class="comment">// apply lambda function on each voxel </span></div><div class="line"><span class="comment">// and store the result in an output image </span></div><div class="line"><a class="code" href="group__meta__algorithm.html#gaf90e6c7b7e426bceecd429783ab79f79">transform</a>(</div><div class="line">      <a class="code" href="namespacecugip.html#a8e680bc72ec57336a56418d892e181f5">const_view</a>(deviceImage), </div><div class="line">      <a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">view</a>(resultImage), </div><div class="line">      []__device__(<span class="keywordtype">int</span> arg) { </div><div class="line">            <span class="keywordflow">return</span> arg * 3.141592f; </div><div class="line">      });</div></div><!-- fragment --><h3><a class="anchor" id="locator_sec"></a>
Locator Access and Shared Memory</h3>
<p>If the input and output views are different and non-overlapping, it means that values from input view will not be changed during the computation, so it is safe to compute a new value based on the values of the other image elements (typically from the neighborhood). For this case, there is a variant of transform algorithm called {<a class="el" href="group__meta__algorithm.html#ga38dfdbac8f92870fd6a2d6cb4a42f1ac">transform_locator()</a>}, which takes a callable operating on the locator anchored in the processed element (instead of its value).</p>
<p>Without further knowledge about access patterns, the most generic version of the algorithm cannot optimize the global memory accesses. If the memory access pattern is known and especially if the elements accessed through the image locators are from the bounded neighborhood of the anchoring element and each element would be loaded multiple times during the computation, then the region accessed by threads from the thread block can be preloaded into shared memory. The callable object passed to the {<a class="el" href="group__meta__algorithm.html#ga38dfdbac8f92870fd6a2d6cb4a42f1ac">transform_locator()</a>} algorithm will then obtain locator which provides access for this preloaded piece of memory instead of access to global memory.</p>
<p>Basic image processing algorithms like convolutions, median denoising, morphological operations, etc. can be implemented using {<a class="el" href="group__meta__algorithm.html#ga38dfdbac8f92870fd6a2d6cb4a42f1ac">transform_locator()</a>} meta-algorithm.</p>
<h2><a class="anchor" id="reduce_sec"></a>
Reduce</h2>
<p>Reduce (fold, accumulate, etc.) is an operation, which recursively combines values into a single result. A typical example is a reduction with addition operator, which is equivalent to a sum of the values from processed range.</p>
<p>Parallel reductions require the operator to be associative. Otherwise, it would possibly return different results for different schedulings.</p>
<p>The implementation follows optimization steps from <b>[Harris2007]</b>} to achieve maximum possible throughput. Slight generalization is needed, because the presented optimized version works on 1D ranges and CUGIP implementation requires image view of arbitrary dimension to be supported.</p>
<h2><a class="anchor" id="scan_sec"></a>
Scan</h2>
<p>Together with reduce comes in hand another operation called {scan}. Its special case is a prefix sum. The scan operation returns reduction of all items up to the computed one and does it for all elements in the processed range.</p>
<p>Application on image views allows other slight extensions. The scan operation can be applied to the sequence of all image view elements, or separately on slices/scan-lines. The latter approach is useful for computation of integral images.</p>
<h1><a class="anchor" id="code_axample_sec"></a>
Code Example</h1>
<div class="fragment"><div class="line"><span class="keywordtype">void</span> gradientMagnitude(<span class="keywordtype">float</span> *aInput, <span class="keywordtype">float</span> *aOutput, <span class="keywordtype">size_t</span> aWidth, <span class="keywordtype">size_t</span> aHeight, <span class="keywordtype">size_t</span> aDepth, <span class="keywordtype">bool</span> aNormalize)</div><div class="line">{</div><div class="line">      <span class="comment">// Wrap the pointers for input/output buffers </span></div><div class="line">      <span class="comment">// into host image views.</span></div><div class="line">      <span class="comment">// No strides available - suppose contiguous storage.</span></div><div class="line">      <span class="keyword">auto</span> inView = <a class="code" href="namespacecugip.html#a94a954913ea5361ca0580c226ab5c6ec">makeConstHostImageView</a>(aInput, <a class="code" href="namespacecugip.html#a488557a70bae897879d9f83d3fd4e28a">vect3i_t</a>(aWidth, aHeight, aDepth));</div><div class="line">      <span class="keyword">auto</span> outView = <a class="code" href="namespacecugip.html#a896681a6efa5bf030fbfecb057f336d0">makeHostImageView</a>(aOutput, <a class="code" href="namespacecugip.html#a488557a70bae897879d9f83d3fd4e28a">vect3i_t</a>(aWidth, aHeight, aDepth));</div><div class="line"></div><div class="line">      <span class="comment">// allocate image for input and output </span></div><div class="line">      <span class="comment">// on the device</span></div><div class="line">      <a class="code" href="classcugip_1_1device__image.html">cugip::device_image&lt;float, 3&gt;</a> inImage(inView.dimensions());</div><div class="line">      <a class="code" href="classcugip_1_1device__image.html">cugip::device_image&lt;float, 3&gt;</a> outImage(inView.dimensions());</div><div class="line"></div><div class="line">      <span class="comment">// copy the data from host input buffer </span></div><div class="line">      <span class="comment">// into its device counterpart</span></div><div class="line">      <a class="code" href="namespacecugip.html#a8f8bd893f8d06a9e9f4d89eadc610d03">cugip::copy</a>(inView, <a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">cugip::view</a>(inImage));</div><div class="line"></div><div class="line">      <span class="comment">// compute the sobel gradient magnitude </span></div><div class="line">      <span class="comment">// approximation (in 3 dimensions)</span></div><div class="line">      <a class="code" href="group__meta__algorithm.html#ga38dfdbac8f92870fd6a2d6cb4a42f1ac">cugip::transform_locator</a>(</div><div class="line">            <a class="code" href="namespacecugip.html#a8e680bc72ec57336a56418d892e181f5">cugip::const_view</a>(inImage), </div><div class="line">            <a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">cugip::view</a>(outImage), </div><div class="line">            sobel_gradient_magnitude&lt;3&gt;());</div><div class="line"></div><div class="line">      <span class="comment">// if desired, scale all the values </span></div><div class="line">      <span class="comment">// into the [0, 1] interval</span></div><div class="line">      <span class="keywordflow">if</span> (aNormalize) {</div><div class="line">            <span class="comment">// find the maximal value by </span></div><div class="line">            <span class="comment">// parallel reduction</span></div><div class="line">            <span class="keyword">auto</span> maxVal = <a class="code" href="namespacecugip.html#a109891c654e30ed29fe3cc2d294e570e">cugip::max</a>(<a class="code" href="namespacecugip.html#a8e680bc72ec57336a56418d892e181f5">cugip::const_view</a>(outImage));</div><div class="line">            <span class="comment">// multiply all the values</span></div><div class="line">            <a class="code" href="group__meta__algorithm.html#ga5b5057c3753b24eebffa1825efe3d781">cugip::for_each</a>(</div><div class="line">                  <a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">cugip::view</a>(outImage), </div><div class="line">                  MultiplyByFactorFunctor&lt;float&gt;(1.0f / maxVal));</div><div class="line">      }</div><div class="line">      <span class="comment">// store to host the results </span></div><div class="line">      <span class="comment">// computed on device</span></div><div class="line">      <a class="code" href="namespacecugip.html#a8f8bd893f8d06a9e9f4d89eadc610d03">cugip::copy</a>(<a class="code" href="namespacecugip.html#a29e6e917a78239974627c5ae40c8e4cd">cugip::view</a>(outImage), outView);</div><div class="line">}     </div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Feb 17 2017 00:13:10 for CUGIP by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
